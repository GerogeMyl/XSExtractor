# XSExtractor
提取新闻、博客等长文本网页的正文工具

  在和许多开发爬虫，特别是抓取新闻资讯等网页的爬虫开发者交流的时候，发现很多人对于怎样去提取页面中的信息感到无从下手。
因此我结合自己在开发爬虫项目时候的用到的一些技术和技巧，将抽取页面信息的主要模块开源出来，供大家参考，
做得不足的地方欢迎拍砖。

先谈谈自己爬虫项目的背景：
 
  项目主要的功能是实时采集经济、财经、政策等咨询和新闻信息（共一万多个信息源），将这些抓取到新闻资讯抽取出来结构化，
然后存储到关系型数据库中，然后再对这些抓取到的新闻资讯进行基于内容的去重、提取关键词、分类等离线处理，最后通过推送引擎推送到各个下游系统以及全文索引系统中。

开发过程中遇到的问题：
>
-  1、信息源太多，每个网站的结构都不一样，怎样从不同结构的网页中抽取需要的新闻信息（新闻标题、新闻时间、新闻内容等）
-  2、需要保存新闻的部分格式，便于将新闻资讯转到富文本编辑器中进行二次编辑。
-  3、需要将新闻资讯中的图片下载下来保存到本地图片服务器。
-  4、如果新闻分页，需要将新闻采集完整。
-  5、由于需要将新闻直接推送（不经过人工编辑）至手机新闻App等系统，所以采集到的新闻内容中不能含有任何杂质，
例如：广告图片、推荐链接、推荐阅读、免责声明、关注微信、来源说明、版权说明、分页标识等。同时，由于财经类型新闻可能含有股票代码
和股票价格等信息，为了不让用户在看到我们的新闻的时候对股票价格有误解，因此新闻中的股票代码和股票价格也需要去除。








未完待续...

